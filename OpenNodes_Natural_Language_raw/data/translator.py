import json
import os
import re
from typing import List, Dict, Optional
import requests
import time

class DeepSeekTranslator:
    def __init__(self, api_key: str, base_url: str = "https://api.deepseek.com"):
        """
        åˆå§‹åŒ–DeepSeekç¿»è¯‘å™¨
        
        Args:
            api_key: DeepSeek APIå¯†é’¥
            base_url: APIåŸºç¡€URLï¼Œé»˜è®¤ä¸ºDeepSeekå®˜æ–¹API
        """
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def read_file(self, file_path: str) -> str:
        """
        è¯»å–æœ¬åœ°æ–‡æœ¬æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        except FileNotFoundError:
            print(f"é”™è¯¯: æ–‡ä»¶ '{file_path}' æœªæ‰¾åˆ°")
            raise
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise
    
    def split_into_chapters(self, text: str) -> List[Dict[str, str]]:
        """
        å°†æ–‡æœ¬æŒ‰ç…§ CHAPTER I.ã€CHAPTER II. ç­‰æ ¼å¼åˆ’åˆ†ç« èŠ‚
        
        Args:
            text: å®Œæ•´æ–‡æœ¬å†…å®¹
            
        Returns:
            ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å«æ ‡é¢˜å’Œå†…å®¹
        """
        chapters = []
        
        # ä¼˜åŒ–ç« èŠ‚åˆ†å‰²æ¨¡å¼ï¼šåŒ¹é… CHAPTER I.ã€CHAPTER II. ç­‰æ ¼å¼
        # æ”¯æŒç½—é©¬æ•°å­— I, II, III, IV, V, VI, VII, VIII, IX, X ç­‰
        chapter_pattern = r'(CHAPTER\s+[IVXLCDM]+\.)'
        
        # æŸ¥æ‰¾æ‰€æœ‰ç« èŠ‚æ ‡é¢˜çš„ä½ç½®
        matches = list(re.finditer(chapter_pattern, text, re.IGNORECASE))
        
        if not matches:
            print("æœªæ£€æµ‹åˆ° CHAPTER X. æ ¼å¼çš„ç« èŠ‚ï¼Œå°è¯•å…¶ä»–æ ¼å¼...")
            # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            alternative_patterns = [
                r'(CHAPTER\s+\d+\.)',  # CHAPTER 1.
                r'(Chapter\s+[IVXLCDM]+\.)',  # Chapter I.
                r'(Chapter\s+\d+\.)',  # Chapter 1.
            ]
            
            for pattern in alternative_patterns:
                matches = list(re.finditer(pattern, text, re.IGNORECASE))
                if matches:
                    print(f"æ£€æµ‹åˆ°æ ¼å¼: {pattern}")
                    break
        
        if not matches:
            print("æœªæ£€æµ‹åˆ°æ ‡å‡†ç« èŠ‚æ ¼å¼ï¼Œå°†æ•´ä¸ªæ–‡æœ¬ä½œä¸ºä¸€ç« å¤„ç†")
            return [{
                'title': 'å®Œæ•´æ–‡æœ¬',
                'content': text.strip(),
                'chapter_number': 1
            }]
        
        print(f"æ£€æµ‹åˆ° {len(matches)} ä¸ªç« èŠ‚")
        
        # æ ¹æ®ç« èŠ‚æ ‡é¢˜åˆ†å‰²æ–‡æœ¬
        for i, match in enumerate(matches):
            chapter_title = match.group().strip()
            
            # è·å–ç« èŠ‚å¼€å§‹ä½ç½®
            start_pos = match.start()
            
            # ç¡®å®šç« èŠ‚å†…å®¹èŒƒå›´
            if i < len(matches) - 1:
                end_pos = matches[i + 1].start()
            else:
                end_pos = len(text)
            
            chapter_content = text[start_pos:end_pos].strip()
            
            # æå–ç½—é©¬æ•°å­—
            roman_num = re.search(r'[IVXLCDM]+', chapter_title, re.IGNORECASE)
            if roman_num:
                chapter_number = self._roman_to_int(roman_num.group())
            else:
                chapter_number = i + 1
            
            chapters.append({
                'title': chapter_title,
                'content': chapter_content,
                'chapter_number': chapter_number,
                'roman_num': roman_num.group() if roman_num else str(i + 1)
            })
            
            print(f"  ç« èŠ‚ {i + 1}: {chapter_title} (ç½—é©¬æ•°å­—: {roman_num.group() if roman_num else 'N/A'})")
        
        return chapters
    
    def _roman_to_int(self, roman: str) -> int:
        """
        ç½—é©¬æ•°å­—è½¬æ¢ä¸ºæ•´æ•°
        
        Args:
            roman: ç½—é©¬æ•°å­—å­—ç¬¦ä¸²
            
        Returns:
            å¯¹åº”çš„æ•´æ•°å€¼
        """
        roman_dict = {
            'I': 1, 'V': 5, 'X': 10, 'L': 50,
            'C': 100, 'D': 500, 'M': 1000
        }
        
        roman = roman.upper()
        total = 0
        prev_value = 0
        
        for char in reversed(roman):
            value = roman_dict.get(char, 0)
            if value < prev_value:
                total -= value
            else:
                total += value
            prev_value = value
            
        return total
    
    def translate_text(self, text: str, target_language: str) -> str:
        """
        è°ƒç”¨DeepSeek APIç¿»è¯‘æ–‡æœ¬
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            target_language: ç›®æ ‡è¯­è¨€ï¼ˆå¦‚ï¼šä¸­æ–‡ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ç­‰ï¼‰
            
        Returns:
            ç¿»è¯‘åçš„æ–‡æœ¬
        """
        # æ„å»ºAPIè¯·æ±‚
        url = f"{self.base_url}/chat/completions"
        
        prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆ{target_language}ã€‚

ç¿»è¯‘è¦æ±‚ï¼š
1. ä¿æŒåŸæ–‡çš„æ ¼å¼ã€æ®µè½ã€ç« èŠ‚æ ‡é¢˜å’Œæ ‡ç‚¹ç¬¦å·
2. äººåã€åœ°åç­‰ä¸“æœ‰åè¯ä¿æŒåŸæ ·ï¼Œé¦–æ¬¡å‡ºç°æ—¶å¯åœ¨æ‹¬å·å†…æ³¨æ˜éŸ³è¯‘
3. ç¡®ä¿ç¿»è¯‘å‡†ç¡®è‡ªç„¶ï¼Œç¬¦åˆ{target_language}çš„è¡¨è¾¾ä¹ æƒ¯
4. ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šã€è¯´æ˜æˆ–æ³¨é‡Š
5. ä¿æŒCHAPTERæ ‡é¢˜æ ¼å¼ä¸å˜ï¼Œåªç¿»è¯‘å†…å®¹

è‹±æ–‡æ–‡æœ¬ï¼š
{text}

{target_language}ç¿»è¯‘ï¼š"""
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.2,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç¿»è¯‘
            "max_tokens": 4000,
            "stream": False
        }
        
        try:
            response = requests.post(url, headers=self.headers, json=payload, timeout=120)
            response.raise_for_status()
            
            result = response.json()
            translated_text = result['choices'][0]['message']['content'].strip()
            
            # ç¡®ä¿ç¿»è¯‘ä»¥CHAPTERæ ‡é¢˜å¼€å§‹
            if not translated_text.startswith("CHAPTER"):
                # æŸ¥æ‰¾CHAPTERæ ‡é¢˜
                chapter_match = re.search(r'(CHAPTER\s+[IVXLCDM]+\.)', text)
                if chapter_match:
                    chapter_title = chapter_match.group()
                    if chapter_title not in translated_text:
                        translated_text = f"{chapter_title}\n\n{translated_text}"
            
            return translated_text
            
        except requests.exceptions.RequestException as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {e}")
            if hasattr(e, 'response') and e.response:
                print(f"å“åº”çŠ¶æ€ç : {e.response.status_code}")
                try:
                    error_detail = e.response.json()
                    print(f"é”™è¯¯è¯¦æƒ…: {error_detail}")
                except:
                    print(f"å“åº”å†…å®¹: {e.response.text[:200]}")
            raise
        except KeyError as e:
            print(f"è§£æAPIå“åº”æ—¶å‡ºé”™: {e}")
            print(f"APIå“åº”: {result}")
            raise
        except Exception as e:
            print(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise
    
    def translate_chapter(self, chapter: Dict, target_language: str, 
                         max_chunk_length: int = 2500) -> Dict:
        """
        ç¿»è¯‘å•ä¸ªç« èŠ‚ï¼Œå¤„ç†é•¿æ–‡æœ¬åˆ†å—
        
        Args:
            chapter: ç« èŠ‚å­—å…¸
            target_language: ç›®æ ‡è¯­è¨€
            max_chunk_length: æ¯ä¸ªç¿»è¯‘å—çš„æœ€å¤§é•¿åº¦
            
        Returns:
            åŒ…å«ç¿»è¯‘åå†…å®¹çš„ç« èŠ‚å­—å…¸
        """
        print(f"\næ­£åœ¨ç¿»è¯‘: {chapter['title']} ({len(chapter['content'])} å­—ç¬¦)")
        
        content = chapter['content']
        
        # å¦‚æœå†…å®¹è¿‡é•¿ï¼Œåˆ†å—ç¿»è¯‘
        if len(content) > max_chunk_length:
            print(f"  ç« èŠ‚å†…å®¹è¾ƒé•¿ï¼Œå°†åˆ†å—ç¿»è¯‘...")
            chunks = self._split_into_chunks(content, max_chunk_length)
            translated_chunks = []
            
            for i, chunk in enumerate(chunks):
                print(f"  ç¿»è¯‘å— {i + 1}/{len(chunks)}...")
                try:
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                    if i > 0:
                        time.sleep(1)
                    
                    translated_chunk = self.translate_text(chunk, target_language)
                    translated_chunks.append(translated_chunk)
                except Exception as e:
                    print(f"  ç¿»è¯‘å— {i + 1} å¤±è´¥: {e}")
                    # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œä¿ç•™åŸæ–‡å¹¶æ ‡è®°
                    translated_chunks.append(f"[ç¿»è¯‘å¤±è´¥éƒ¨åˆ†ï¼Œä¿ç•™åŸæ–‡]\n{chunk}")
                
            translated_content = '\n\n'.join(translated_chunks)
        else:
            translated_content = self.translate_text(content, target_language)
        
        # æå–ç¿»è¯‘åçš„æ ‡é¢˜
        translated_title = self._extract_translated_title(translated_content, chapter['title'])
        
        return {
            'original_title': chapter['title'],
            'translated_title': translated_title,
            'original_content': content,
            'translated_content': translated_content,
            'chapter_number': chapter['chapter_number'],
            'roman_num': chapter.get('roman_num', str(chapter['chapter_number']))
        }
    
    def _extract_translated_title(self, translated_content: str, original_title: str) -> str:
        """
        ä»ç¿»è¯‘å†…å®¹ä¸­æå–ç« èŠ‚æ ‡é¢˜
        
        Args:
            translated_content: ç¿»è¯‘åçš„å†…å®¹
            original_title: åŸå§‹æ ‡é¢˜
            
        Returns:
            æå–çš„æ ‡é¢˜
        """
        # å°è¯•ä»ç¿»è¯‘å†…å®¹ä¸­æå–CHAPTERæ ‡é¢˜
        title_patterns = [
            r'(CHAPTER\s+[IVXLCDM]+\.)',
            r'(ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\s*ç« )',
            r'(Chapter\s+[IVXLCDM]+\.)',
            r'(ç« èŠ‚\s+[IVXLCDM]+\.)',
        ]
        
        for pattern in title_patterns:
            match = re.search(pattern, translated_content, re.IGNORECASE)
            if match:
                return match.group()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›åŸå§‹æ ‡é¢˜
        return original_title
    
    def _split_into_chunks(self, text: str, max_length: int) -> List[str]:
        """
        å°†æ–‡æœ¬åˆ†å‰²æˆé€‚åˆç¿»è¯‘çš„å—ï¼Œä¿æŒæ®µè½å®Œæ•´
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            max_length: æ¯ä¸ªå—çš„æœ€å¤§é•¿åº¦
            
        Returns:
            æ–‡æœ¬å—åˆ—è¡¨
        """
        chunks = []
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = re.split(r'(\n\s*\n)', text)
        
        current_chunk = ""
        for i in range(0, len(paragraphs), 2):
            paragraph = paragraphs[i]
            separator = paragraphs[i + 1] if i + 1 < len(paragraphs) else ""
            
            # å¦‚æœå½“å‰æ®µè½åŠ ä¸Šåˆ†éš”ç¬¦çš„é•¿åº¦ä¸è¶…è¿‡é™åˆ¶
            if len(current_chunk) + len(paragraph) + len(separator) <= max_length:
                current_chunk += paragraph + separator
            else:
                # ä¿å­˜å½“å‰å—
                if current_chunk:
                    chunks.append(current_chunk.strip())
                
                # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡æœ€å¤§é•¿åº¦ï¼ŒæŒ‰å¥å­åˆ†å‰²
                if len(paragraph) > max_length:
                    sentences = re.split(r'(?<=[.!?])\s+', paragraph)
                    temp_chunk = ""
                    for sentence in sentences:
                        if len(temp_chunk) + len(sentence) + 2 <= max_length:
                            if temp_chunk:
                                temp_chunk += ' ' + sentence
                            else:
                                temp_chunk = sentence
                        else:
                            if temp_chunk:
                                chunks.append(temp_chunk.strip())
                            temp_chunk = sentence
                    if temp_chunk:
                        chunks.append(temp_chunk.strip())
                    current_chunk = separator
                else:
                    current_chunk = paragraph + separator
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def save_translation(self, translated_chapters: List[Dict], 
                        output_dir: str, target_language: str, 
                        save_format: str = 'both'):
        """
        ä¿å­˜ç¿»è¯‘ç»“æœ
        
        Args:
            translated_chapters: ç¿»è¯‘åçš„ç« èŠ‚åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            target_language: ç›®æ ‡è¯­è¨€
            save_format: ä¿å­˜æ ¼å¼ ('txt', 'json', æˆ– 'both')
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        safe_lang = re.sub(r'[^\w\s-]', '', target_language).replace(' ', '_').lower()
        base_filename = f"alice_{safe_lang}"
        
        # ä¿å­˜å®Œæ•´ç¿»è¯‘æ–‡ä»¶
        if save_format in ['txt', 'both']:
            txt_path = os.path.join(output_dir, f"{base_filename}_complete.txt")
            with open(txt_path, 'w', encoding='utf-8') as f:
                for chapter in translated_chapters:
                    f.write(f"{chapter['translated_title']}\n")
                    f.write("-" * 60 + "\n\n")
                    f.write(chapter['translated_content'])
                    f.write("\n\n" + "=" * 80 + "\n\n")
            
            print(f"\nå®Œæ•´ç¿»è¯‘å·²ä¿å­˜ä¸ºTXTæ–‡ä»¶: {txt_path}")
        
        # ä¿å­˜JSONæ ¼å¼ï¼ˆåŒ…å«åŸæ–‡å’Œè¯‘æ–‡ï¼‰
        if save_format in ['json', 'both']:
            json_path = os.path.join(output_dir, f"{base_filename}_bilingual.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(translated_chapters, f, ensure_ascii=False, indent=2)
            
            print(f"åŒè¯­å¯¹ç…§å·²ä¿å­˜ä¸ºJSONæ–‡ä»¶: {json_path}")
        
        # ä¿å­˜çº¯è¯‘æ–‡æ–‡ä»¶ï¼ˆæ— é¢å¤–åˆ†éš”ç¬¦ï¼‰
        txt_clean_path = os.path.join(output_dir, f"{base_filename}_clean.txt")
        with open(txt_clean_path, 'w', encoding='utf-8') as f:
            for chapter in translated_chapters:
                f.write(chapter['translated_content'])
                f.write("\n\n")
        
        print(f"çº¯å‡€è¯‘æ–‡å·²ä¿å­˜ä¸º: {txt_clean_path}")
        
        # åŒæ—¶ä¿å­˜å•ä¸ªç« èŠ‚æ–‡ä»¶
        chapters_dir = os.path.join(output_dir, "individual_chapters")
        os.makedirs(chapters_dir, exist_ok=True)
        
        print(f"\næ­£åœ¨ä¿å­˜å•ä¸ªç« èŠ‚æ–‡ä»¶...")
        for chapter in translated_chapters:
            chapter_num = chapter['chapter_number']
            roman_num = chapter.get('roman_num', str(chapter_num))
            
            # ä¿å­˜è¯‘æ–‡
            translated_filename = f"chapter_{roman_num}_{safe_lang}.txt"
            translated_path = os.path.join(chapters_dir, translated_filename)
            
            with open(translated_path, 'w', encoding='utf-8') as f:
                f.write(chapter['translated_content'])
            
            # ä¿å­˜åŒè¯­å¯¹ç…§
            bilingual_filename = f"chapter_{roman_num}_bilingual.txt"
            bilingual_path = os.path.join(chapters_dir, bilingual_filename)
            
            with open(bilingual_path, 'w', encoding='utf-8') as f:
                f.write("=" * 40 + " è‹±æ–‡åŸæ–‡ " + "=" * 40 + "\n")
                f.write(chapter['original_content'])
                f.write("\n\n" + "=" * 40 + f" {target_language}è¯‘æ–‡ " + "=" * 40 + "\n")
                f.write(chapter['translated_content'])
        
        print(f"å•ä¸ªç« èŠ‚æ–‡ä»¶å·²ä¿å­˜è‡³: {chapters_dir}")
        
        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        self._generate_summary(translated_chapters, output_dir, target_language)
    
    def _generate_summary(self, chapters: List[Dict], output_dir: str, target_language: str):
        """
        ç”Ÿæˆç¿»è¯‘æ‘˜è¦æŠ¥å‘Š
        
        Args:
            chapters: ç« èŠ‚åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            target_language: ç›®æ ‡è¯­è¨€
        """
        report_path = os.path.join(output_dir, "translation_summary.txt")
        
        total_original_chars = sum(len(chapter['original_content']) for chapter in chapters)
        total_translated_chars = sum(len(chapter['translated_content']) for chapter in chapters)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write(f"ã€Šçˆ±ä¸½ä¸æ¢¦æ¸¸ä»™å¢ƒã€‹{target_language}ç¿»è¯‘æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"ç¿»è¯‘åŸºæœ¬ä¿¡æ¯ï¼š\n")
            f.write(f"- ç›®æ ‡è¯­è¨€: {target_language}\n")
            f.write(f"- ç« èŠ‚æ•°é‡: {len(chapters)}\n")
            f.write(f"- åŸæ–‡æ€»å­—ç¬¦æ•°: {total_original_chars:,}\n")
            f.write(f"- è¯‘æ–‡æ€»å­—ç¬¦æ•°: {total_translated_chars:,}\n")
            f.write(f"- ç¿»è¯‘æ¯”ç‡: {total_translated_chars/total_original_chars:.2f}\n\n")
            
            f.write("ç« èŠ‚è¯¦æƒ…ï¼š\n")
            f.write("-" * 60 + "\n")
            
            for chapter in chapters:
                orig_len = len(chapter['original_content'])
                trans_len = len(chapter['translated_content'])
                ratio = trans_len / orig_len if orig_len > 0 else 0
                
                f.write(f"ç¬¬{chapter['chapter_number']}ç«  ({chapter.get('roman_num', 'N/A')})\n")
                f.write(f"  æ ‡é¢˜: {chapter['original_title']} â†’ {chapter['translated_title']}\n")
                f.write(f"  åŸæ–‡é•¿åº¦: {orig_len:,} å­—ç¬¦\n")
                f.write(f"  è¯‘æ–‡é•¿åº¦: {trans_len:,} å­—ç¬¦\n")
                f.write(f"  é•¿åº¦æ¯”ç‡: {ratio:.2f}\n")
                f.write("-" * 40 + "\n")
            
            f.write(f"\næŠ¥å‘Šç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        print(f"ç¿»è¯‘æ‘˜è¦æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    API_KEY = "sk-6fc1143a5b8c4859a8c659c0589eca9f"  # æ›¿æ¢ä¸ºä½ çš„APIå¯†é’¥
    INPUT_FILE = "merge_all.txt"  # è¾“å…¥æ–‡ä»¶è·¯å¾„
    lanList = ['Chinese', 'French', 'German', 'Russian', 'Japanese', 'Spanish', 'Italian']
    TARGET_LANGUAGE = lanList[6] # ç›®æ ‡è¯­è¨€: 0, 1, 2, 3, 4, 5, 6
    OUTPUT_DIR = "alice_translation"  # è¾“å‡ºç›®å½•
    
    print("ã€Šçˆ±ä¸½ä¸æ¢¦æ¸¸ä»™å¢ƒã€‹ç« èŠ‚ç¿»è¯‘å·¥å…·")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç¿»è¯‘å™¨
    translator = DeepSeekTranslator(api_key=API_KEY)
    
    try:
        # 1. è¯»å–æ–‡ä»¶
        print("æ­¥éª¤1: æ­£åœ¨è¯»å–æ–‡ä»¶...")
        text_content = translator.read_file(INPUT_FILE)
        print(f"âœ“ æ–‡ä»¶è¯»å–å®Œæˆï¼Œæ€»å­—ç¬¦æ•°: {len(text_content):,}")
        
        # 2. åˆ’åˆ†ç« èŠ‚
        print("\næ­¥éª¤2: æ­£åœ¨åˆ†æç« èŠ‚ç»“æ„...")
        chapters = translator.split_into_chapters(text_content)
        print(f"âœ“ å…±è¯†åˆ«åˆ° {len(chapters)} ä¸ªç« èŠ‚")
        
        # 3. ç¿»è¯‘æ¯ä¸ªç« èŠ‚
        print(f"\næ­¥éª¤3: å¼€å§‹ç¿»è¯‘ä¸º {TARGET_LANGUAGE}...")
        print("=" * 50)
        
        translated_chapters = []
        
        for i, chapter in enumerate(chapters):
            try:
                print(f"\n[{i + 1}/{len(chapters)}] ", end="")
                translated_chapter = translator.translate_chapter(
                    chapter, 
                    TARGET_LANGUAGE
                )
                translated_chapters.append(translated_chapter)
                print(f"âœ“ å®Œæˆ: {chapter['title']}")
                
                # æ·»åŠ ç« èŠ‚é—´å»¶è¿Ÿ
                if i < len(chapters) - 1:
                    time.sleep(2)  # é¿å…APIé¢‘ç‡é™åˆ¶
                    
            except Exception as e:
                print(f"\nâœ— ç« èŠ‚ç¿»è¯‘å¤±è´¥: {chapter['title']}")
                print(f"   é”™è¯¯ä¿¡æ¯: {e}")
                print("   å°†è·³è¿‡æ­¤ç« èŠ‚ç»§ç»­å¤„ç†...")
                
                # æ·»åŠ é”™è¯¯ç« èŠ‚å ä½ç¬¦
                translated_chapters.append({
                    'original_title': chapter['title'],
                    'translated_title': chapter['title'] + " [ç¿»è¯‘å¤±è´¥]",
                    'original_content': chapter['content'],
                    'translated_content': f"ã€ç¿»è¯‘å¤±è´¥ã€‘\n\n{chapter['content']}",
                    'chapter_number': chapter['chapter_number'],
                    'roman_num': chapter.get('roman_num', str(chapter['chapter_number']))
                })
        
        # 4. ä¿å­˜ç»“æœ
        print("\n" + "=" * 50)
        print("æ­¥éª¤4: æ­£åœ¨ä¿å­˜ç¿»è¯‘ç»“æœ...")
        translator.save_translation(
            translated_chapters,
            OUTPUT_DIR,
            TARGET_LANGUAGE,
            save_format='both'
        )
        
        print("\n" + "=" * 50)
        print("ğŸ‰ ç¿»è¯‘ä»»åŠ¡å®Œæˆï¼")
        print(f"æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜è‡³: {os.path.abspath(OUTPUT_DIR)}")
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def quick_translate():
    """å¿«é€Ÿç¿»è¯‘å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    API_KEY = input("è¯·è¾“å…¥DeepSeek APIå¯†é’¥: ").strip()
    TARGET_LANGUAGE = input("è¯·è¾“å…¥ç›®æ ‡è¯­è¨€ï¼ˆå¦‚ï¼šä¸­æ–‡ã€æ—¥è¯­ã€æ³•è¯­ï¼‰: ").strip()
    INPUT_FILE = "alice_english.txt"
    
    if not os.path.exists(INPUT_FILE):
        print(f"é”™è¯¯: æ–‡ä»¶ {INPUT_FILE} ä¸å­˜åœ¨ï¼")
        return
    
    translator = DeepSeekTranslator(api_key=API_KEY)
    
    # è¯»å–å¹¶åˆ†å‰²ç« èŠ‚
    text = translator.read_file(INPUT_FILE)
    chapters = translator.split_into_chapters(text)
    
    print(f"\nå¼€å§‹ç¿»è¯‘ {len(chapters)} ä¸ªç« èŠ‚...")
    
    # åªç¿»è¯‘å‰3ç« ä½œä¸ºç¤ºä¾‹
    sample_chapters = chapters[:3]
    translated = []
    
    for chapter in sample_chapters:
        print(f"ç¿»è¯‘: {chapter['title']}")
        try:
            result = translator.translate_chapter(chapter, TARGET_LANGUAGE)
            translated.append(result)
        except Exception as e:
            print(f"  å¤±è´¥: {e}")
    
    # ä¿å­˜ç¤ºä¾‹
    output_dir = "sample_translation"
    translator.save_translation(translated, output_dir, TARGET_LANGUAGE, save_format='txt')
    
    print(f"\nç¤ºä¾‹ç¿»è¯‘å·²ä¿å­˜åˆ°: {output_dir}")

if __name__ == "__main__":
    print("è¯·é€‰æ‹©æ¨¡å¼:")
    print("1. å®Œæ•´ç¿»è¯‘ï¼ˆæ‰€æœ‰ç« èŠ‚ï¼‰")
    print("2. å¿«é€Ÿæµ‹è¯•ï¼ˆä»…ç¿»è¯‘å‰3ç« ï¼‰")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
    
    if choice == "2":
        quick_translate()
    else:
        main()