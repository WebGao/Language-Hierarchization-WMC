# Language Hierarchization and Human Working Memory Limits

This repository contains the source code for the manuscript:

**"Language Hierarchization Provides the Optimal Solution to Human Working Memory Limits"**

## ğŸ“‚ Repository Structure

The repository is organized into three main modules, each corresponding to a specific corpus analyzed in the study. Each module contains its own data processing and analysis scripts.

```text
Language-Hierarchization-WMC
â”œâ”€â”€ OpenNodes_Alice               # Multilingual analysis of "Alice's Adventures in Wonderland"
â”‚   â”œâ”€â”€ data/                     # Processed text data for 8 languages
â”‚   â””â”€â”€ main.py                   # Main analysis script for Alice corpus
â”œâ”€â”€ OpenNodes_Child               # Analysis of the Child Spoken Language Corpus (Ages 3-8)
â”‚   â”œâ”€â”€ data/                     # Longitudinal spoken language data
â”‚   â””â”€â”€ main.py                   # Main analysis script for developmental data
â””â”€â”€ OpenNodes_Natural_Language    # Analysis of the Classics Corpus (English)
    â”œâ”€â”€ data/                     # Large-scale natural language dataset
    â””â”€â”€ main.py                   # Main analysis script for adult natural language

```

## ğŸ“Š Datasets

1. **OpenNodes_Natural_Language (Classics Corpus):** A large-scale English corpus consisting of approximately 34,995 sentences, used to validate the hierarchization theory in adult natural language.
2. **OpenNodes_Alice (Alice Corpus):** A multilingual dataset covering 8 languages (English, Chinese, French, German, Russian, Japanese, Italian, and Spanish) to test the cross-linguistic universality of the optimal solution.
3. **OpenNodes_Child (Child Spoken Language):** Developmental data categorized by age (3-8 years old) to examine how the hierarchization strategy evolves alongside working memory capacity.

## ğŸš€ Getting Started

### Prerequisites

* Python 3.8 or higher
* Required packages: `numpy`, `pandas`, `scipy`, `matplotlib`, `stanza` (Installation: `pip install numpy pandas scipy matplotlib stanza`)

### Running the Analysis

Each module is self-contained. You can replicate the results presented in the paper by running the `main.py` script within each directory.

For example, to analyze the Alice Corpus:

```bash
cd OpenNodes_Alice
python main.py

```

To analyze the Child Spoken Language data:

```bash
cd OpenNodes_Child
python main.py

```

<!-- ## âš™ï¸ Core Methodology

The code implements:

* **Maximum Likelihood Estimation (MLE):** Calculating the working memory capacity () from linguistic structures.
* **Entropy Calculation:** Measuring the information transfer efficiency under different processing mechanisms (Linear vs. Hierarchical).
* **Optimization Validation:** Demonstrating how language hierarchization minimizes cognitive load while maximizing information density. -->

<!-- ## ğŸ“œ Citation

If you use this code or data in your research, please cite:

> *Chen, L., Gao, W., Wu, J., Wu, J., & Friederici, A. D. (2026). Language Hierarchization Provides the Optimal Solution to Human Working Memory Limits. Nature (under review).* -->

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](https://www.google.com/search?q=LICENSE) file for details.

## âœ‰ï¸ Contact

For questions regarding the code or data, please contact the corresponding authors:

* Prof. Dr. Luyao Chen (harry-luyao.chen@polyu.edu.hk)
* Dr. Weibo Gao (weibogao@mail.ustc.edu.cn)
